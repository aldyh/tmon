#+STARTUP: showall

* Design review: tmon project

This document is a critical engineering and design review of the tmon
codebase, written with "fresh eyes" after the core implementation was
complete.

** Original request

#+begin_quote
i want you to look at this project with fresh eyes (everything but the
internal structure of panel/, as that's just a demo). give me honest
feedback on the overall feel, what works, what doesn't, what to
continue doing in future projects, what to avoid in future work. be
very critical as designer. i want feedback from a design and
engineering stand point. write your analysis by filling out the rest of
this file... on a branch.
#+end_quote

** Executive summary

This project succeeds at what it sets out to do: a simple, testable
temperature monitoring system. The architecture is clean and the
code is readable. After reviewing the full codebase, I found no
fundamental design flaws.

The main areas for improvement are around consistency and a few missed
opportunities for simplification. The codebase shows evidence of
iterative refinement (the TODO.org history is instructive), and most
rough edges have been smoothed out.

Overall grade: *B+/A-*. This is solid, professional work that
demonstrates restraint and good engineering judgment.

** What works well

*** Clear separation of concerns

The module boundaries are well-drawn:

| Module      | Responsibility                         |
|-------------+----------------------------------------|
| protocol.py | Frame encoding/decoding, CRC           |
| bus.py      | Serial I/O abstraction                 |
| poller.py   | Polling logic, reading construction    |
| storage.py  | SQLite persistence                     |
| daemon.py   | CLI, signal handling, main loop        |
| config.py   | Configuration loading and validation   |

Each module can be understood in isolation. There are no circular
dependencies. The dependency graph flows cleanly downward:
daemon -> poller -> bus, storage, protocol -> config.

*** Testing strategy is exemplary

The project demonstrates how to test embedded systems code without hardware:

1. *Unit tests with fakes*: ~FakeBus~ is a proper test double, not a
   mock. It records sent data and returns canned responses. Tests
   read clearly and don't depend on mock internals.

2. *x86 Unity tests for C*: The protocol layer compiles and runs on
   the host. This catches bugs before they reach hardware.

3. *Integration tests with socat*: The ~simulator.py~ + ~socat~
   pattern tests the actual daemon binary against a virtual bus.
   This exercises code paths that unit tests miss.

This three-layer approach (unit, x86-native, integration) is the
right model for any hardware-adjacent project.

*** Protocol design is fit for purpose

The custom binary protocol was the correct choice. MODBUS would have
brought:
- Register maps the system doesn't need
- Function codes the system doesn't use
- Exception responses adding complexity
- Third-party library dependencies

Instead, the protocol is purpose-built:
- Fixed 8-byte REPLY payload -- no variable parsing
- CRC-16/MODBUS -- well-documented, testable
- Single command pair (POLL/REPLY) -- matches the use case exactly

The protocol.org specification with worked examples is documentation
done right.

*** Discipline on scope

What's *not* in this codebase is as important as what is:

- No plugin architecture
- No multi-database abstraction
- No configuration GUI
- No "enterprise" features
- No async/await complexity

The daemon is a straightforward loop: poll, store, sleep, repeat.
This simplicity is a feature, not a limitation.

*** Documentation practices

Several good patterns:

1. *Executable docstring examples*: The ~>>>~ examples in docstrings
   serve as both documentation and informal tests.

2. *Single schema source*: After cleanup, the schema lives in
   ~schema/readings.sql~ with references elsewhere. This is the
   right approach.

3. *TODO.org as project diary*: The "Notes" sections on completed
   items preserve decision rationale. This is valuable context for
   future maintainers.

4. *Protocol spec with worked examples*: The byte-by-byte breakdown
   in protocol.org eliminates ambiguity.

*** The "no default arguments" rule

This project guideline makes code greppable. Every call site shows
all parameters:

#+begin_src python
Poller(bus, storage, [1, 2, 3])  # clear
Storage(":memory:")              # clear
#+end_src

vs. hypothetical:

#+begin_src python
Poller(bus)  # what are the slaves?
Storage()    # where's the data going?
#+end_src

** What doesn't work (or could be better)
*** DONE Return type inconsistency: dict vs dataclass

Note: Fix this.  Use dataclasses.

~decode_frame()~ returns a ~Frame~ dataclass:

#+begin_src python
@dataclass
class Frame:
    addr: int
    cmd: int
    payload: bytes
#+end_src

But ~poller.poll()~ returns a plain dict:

#+begin_src python
return {
    "addr": addr,
    "temp_0": temps[0],
    ...
}
#+end_src

And ~storage.fetch()~ returns ~list[dict]~.

The inconsistency is minor but noticeable. Either use dataclasses
throughout (cleaner) or dicts throughout (simpler). The current mix
adds cognitive load.

If I were to pick: dicts for database rows (they *are* dynamic), but
a ~Reading~ dataclass for ~poll()~ return values.

*** DONE Simulator hardcodes address

Note: Fix this.  Accept address as a command line arg, but if you can implement multiple addresses cheaply (very succinctly and it looks better, than do that).  Don't bloat the software, but make it elegant.

~simulator.py~ has:

#+begin_src python
ADDR = 3
#+end_src

But the config file lists slaves ~[1, 2, 3]~. The simulator only
responds as slave 3. This works for testing but is surprising.

Either:
- Document this explicitly in the simulator docstring
- Accept address as a command-line argument
- Support multiple addresses (probably overkill)

*** Error messages could be more actionable

~config.py~ validation produces messages like:

#+begin_example
ValueError: slaves must be a list of ints
#+end_example

Better:

#+begin_example
ValueError: config key 'slaves' must be a list of ints, got str
#+end_example

The extra context helps when debugging configuration issues.
Similarly for missing keys: which file was being parsed?

*** ESP32 main.cpp is a stub

The slave firmware is incomplete:

#+begin_src cpp
void setup (void) {
  /* TODO: initialize serial, RS-485 transceiver, ADC pins */
}
void loop (void) {
  /* TODO: listen for poll request, send response */
}
#+end_src

The protocol layer (~protocol.c~, ~protocol.h~) is complete and
tested, but the actual device bring-up is unfinished. This is fine
for a "master first" development approach, but the project isn't
deployable yet.

*** DONE Storage timestamps are strings

Note: Fix this.  Unix timestamps is ok.  Make sure export to CSV in panel/ still works correctly, cause the CSV consumer definitely doesn't want to see a unix timestamp.

~storage.py~ stores timestamps as ISO-8601 strings:

#+begin_src python
ts = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
#+end_src

SQLite can store these, and they sort correctly, but:
- Queries involving time ranges need string comparison
- Parsing timestamps on read requires ~datetime.fromisoformat()~
- Storage is less efficient than Unix epoch integers

For a small-scale project this is fine. For a larger one, consider
Unix timestamps (INTEGER) with conversion at the boundary.

*** DONE Bus timeout is a module-level constant

Note: Fix this.  It should be in toml.

~BUS_TIMEOUT_MS = 200~ in ~config.py~ is not configurable via TOML.
But ~baudrate~ (which arguably matters less) *is* in the config file.

If 200ms is always correct for 9600 baud, document that relationship.
If it might need tuning for different setups, add it to the config.

** Continue doing in future projects

*** Write fakes, not mocks

~FakeBus~ is better than ~unittest.mock.Mock()~:
- Has explicit, predictable behavior
- Can be inspected (~bus.sent~)
- Tests read as specifications, not implementation details

Prefer hand-written fakes for core interfaces.

*** Test protocol code on x86

Compiling embedded code for the host catches bugs early. The Unity
tests for ~protocol.c~ run in milliseconds and don't require
hardware. This pattern applies to any embedded project.

*** Keep documentation executable

The docstring examples with ~>>>~ are trustworthy because they can
run. Prose lies; code doesn't.

*** Use org-mode for living documents

~PLAN.org~ with its checklist and ~TODO.org~ with its "Notes"
sections work well for tracking project evolution. The format is
readable, greppable, and version-controllable.

*** Start with the poller, not the device

This project developed master-first: protocol spec, Python
implementation, tests, simulator, daemon, *then* ESP32 firmware.
This is the right order. You can validate the entire data path
before touching hardware.

*** Keep dependencies minimal

The master daemon needs only ~pyserial~ beyond stdlib. This makes
deployment trivial and reduces security surface.

** Avoid in future work

*** Mixing structured types (dataclass) with unstructured (dict)

Pick one pattern for return values and stick with it. Mixed usage
creates confusion about what's typed and what isn't.

*** Hardcoding test parameters that could be arguments

The simulator's fixed address is a papercut. Make test tools
configurable from the start.

*** String timestamps in databases

Unix epoch integers are more efficient and easier to work with.
Convert to human-readable at display time, not storage time.

*** Leaving firmware as stubs

The ESP32 main.cpp is TODO-only. Either complete it or remove the
expectation that the project is functional end-to-end. A stub
suggests work-in-progress; document the actual state.

*** Over-engineering validation

~config.py~ has ~_require_str~ and ~_require_int~ helpers. For five
fields, this is fine. For more, consider a declarative schema. But
don't add a schema library preemptively -- YAGNI.

** Minor observations

- GNU C style is applied consistently in the slave code.
- The Makefile is clean and self-documenting.
- WAL mode on SQLite is the right default.
- The 200ms timeout is reasonable for 9600 baud (~1.04ms/byte worst case).
- The panel demo is appropriately isolated from master code.
- Constants are well-named and centralized in ~protocol.py~.
- The ~is_valid_address()~ helper prevents address range bugs.

** Conclusion

This is a well-designed small system. The architecture is sound, the
testing strategy is excellent, and the code is readable. The
criticisms above are refinements, not fundamental problems.

The project demonstrates that embedded systems can be developed
test-first without hardware. It also shows that scope discipline --
saying "no" to features -- results in maintainable code.

If deployed with completed ESP32 firmware, this would be a reliable,
low-maintenance monitoring system. The foundation is solid.
